{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertech RSS Markdown Converter\n",
    "\n",
    "This script fetches XML files from RSS feed URLs and formats them into readable markdown files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s]: %(message)s\")\n",
    "\n",
    "XML_SAVE_DIR = os.environ.get('XML_SAVE_DIR', '/Users/blaed/Documents/GitHub/hypertech-fosai/notebooks/xml')\n",
    "MD_SAVE_DIR = os.environ.get('MD_SAVE_DIR', '/Users/blaed/Documents/GitHub/hypertech-fosai/notebooks/md')\n",
    "RSS_URLS = [\n",
    "    \"https://allainews.com/feed/\",\n",
    "    \"https://analyticsvidhya.com/blog/category/machine-learning/feed/\",\n",
    "    \"https://aws.amazon.com/blogs/machine-learning/feed\",\n",
    "    \"https://bair.berkeley.edu/blog/feed.xml\",\n",
    "    \"https://blog.google/technology/ai/rss\",\n",
    "    \"https://deepmind.com/blog/rss.xml\",\n",
    "    \"https://feeds.feedburner.com/kdnuggets-data-mining-analytics\",\n",
    "    \"https://jamesg.blog/openai.xml\",\n",
    "    \"https://lexfridman.com/feed/podcast/\",\n",
    "    \"https://marktechpost.com/feed\",\n",
    "    \"https://mltechniques.com/feed\",\n",
    "    \"https://news.mit.edu/topic/mitartificial-intelligence2-rss.xml\",\n",
    "    \"https://nvidianews.nvidia.com/releases.xml\"\n",
    "]\n",
    "\n",
    "def generate_md_preamble() -> str:\n",
    "    return \"\"\"---\n",
    "# Hypertech News Report\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def generate_md_postamble() -> str:\n",
    "    return \"\"\"---\n",
    "##### Disclaimer: This report was generated from third-party sources and may be subject to change. Always refer to the original source for the most up-to-date information.\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def sanitize_for_filename(title: str) -> str:\n",
    "    forbidden_chars = ['/', '\\\\', '?', '%', '*', ':', '|', '\"', '<', '>', '#']\n",
    "    for ch in forbidden_chars:\n",
    "        title = title.replace(ch, '_')\n",
    "    return title\n",
    "\n",
    "def fetch_raw_rss(url: str) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch RSS feed from {url}. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_file_name(url: str) -> str:\n",
    "    domain = (url.split(\"//\") + [\"\"])[1].split(\"/\")[0]\n",
    "    return f\"{domain}.xml\"\n",
    "\n",
    "def save_to_file(content: str, directory: str, file_name: str) -> str:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    filepath = os.path.join(directory, file_name)\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "    return filepath\n",
    "\n",
    "def extract_xml_content(element, tag: str) -> str:\n",
    "    found = element.find(tag)\n",
    "    return found.text if found is not None and found.text else \"\"\n",
    "\n",
    "def convert_item_to_markdown(item) -> (str, str):\n",
    "    item_title = extract_xml_content(item, 'title')\n",
    "    item_link = extract_xml_content(item, 'link')\n",
    "    item_description = extract_xml_content(item, 'description')\n",
    "\n",
    "    markdown_section = \"\"\n",
    "    if item_title and item_link:\n",
    "        markdown_section += f\"## {item_title}\\n[Source]({item_link})\\n\"\n",
    "        if item_description:\n",
    "            markdown_section += f\"\\n{item_description}\\n\"\n",
    "        \n",
    "        markdown_section += f\"\\n\\n[Click Here to Learn More]({item_link})\\n\\n\"\n",
    "\n",
    "    return markdown_section, item_title\n",
    "\n",
    "def xml_to_markdown_sections(xml_data: str) -> list:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_data)\n",
    "    except ET.ParseError:\n",
    "        logging.error(\"Error parsing XML data.\")\n",
    "        return []\n",
    "\n",
    "    channel_title = extract_xml_content(root, 'channel/title')\n",
    "    channel_description = extract_xml_content(root, 'channel/description')\n",
    "    header = f\"# {channel_title or 'Title Missing'}\\n\\n{channel_description or 'Description Missing'}\\n\\n\"\n",
    "\n",
    "    markdown_sections = [(header, \"Header\")]\n",
    "    for item in root.findall('channel/item'):\n",
    "        content, title = convert_item_to_markdown(item)\n",
    "        markdown_sections.append((content, title))\n",
    "\n",
    "    return markdown_sections\n",
    "\n",
    "def generate_md_save_dir(base_dir, parent_file_name):\n",
    "    parent_name = os.path.splitext(parent_file_name)[0]\n",
    "    return os.path.join(base_dir, parent_name)\n",
    "\n",
    "def save_master_markdown_file(content_list, directory, file_name):\n",
    "    master_content = \"\"\n",
    "    for section in content_list:\n",
    "        section_content = section.replace(generate_md_preamble(), \"\").replace(generate_md_postamble(), \"\")\n",
    "        master_content += section_content\n",
    "    master_content += generate_md_postamble()\n",
    "    return save_to_file(master_content, directory, file_name)\n",
    "\n",
    "def main():\n",
    "    for rss_url in RSS_URLS:\n",
    "        xml_content = fetch_raw_rss(rss_url)\n",
    "        if xml_content:\n",
    "            file_name = generate_file_name(rss_url)\n",
    "            xml_filepath = save_to_file(xml_content, XML_SAVE_DIR, file_name)\n",
    "            logging.info(f\"Saved RSS feed from {rss_url} to {xml_filepath}\")\n",
    "\n",
    "            current_md_save_dir = generate_md_save_dir(MD_SAVE_DIR, file_name)\n",
    "            markdown_sections = xml_to_markdown_sections(xml_content)\n",
    "            \n",
    "            master_markdown_content_list = []\n",
    "            \n",
    "            for idx, (markdown_section, section_title) in enumerate(markdown_sections, 1):\n",
    "                sanitized_title = sanitize_for_filename(section_title) if section_title else \"section\"\n",
    "                md_file_name = file_name.replace(\".xml\", f\"-{sanitized_title}.md\")\n",
    "\n",
    "                markdown_with_preamble = generate_md_preamble() + markdown_section + generate_md_postamble()\n",
    "                master_markdown_content_list.append(markdown_with_preamble)\n",
    "\n",
    "                md_filepath = save_to_file(markdown_with_preamble, current_md_save_dir, md_file_name)\n",
    "                logging.info(f\"Saved markdown section {idx} from {rss_url} to: {md_filepath}\")\n",
    "            \n",
    "            master_md_filename = file_name.replace(\".xml\", \"-master.md\")\n",
    "            save_master_markdown_file(master_markdown_content_list, current_md_save_dir, master_md_filename)\n",
    "            logging.info(f\"Saved master markdown file for {rss_url} to: {os.path.join(current_md_save_dir, master_md_filename)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
